{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d989992-a9d3-4fc7-920b-5dab64ca227e",
   "metadata": {},
   "source": [
    "# Pixel Finder\n",
    "## Finding Pixels you Want\n",
    "### A more in-depth but slower searcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec669e1-c205-47fe-8a4e-9bbb5696e27c",
   "metadata": {},
   "source": [
    "This notebook takes a list of cubes (likely generated from the DatabaseSearcher) and goes though each cube looking for pixels that meet some kind of specific criteria. It then prints those pixels and a lot of data about said pixels to a file. \n",
    "\n",
    "The recorded pixel values are: \n",
    "\n",
    "0: cube number\n",
    "\n",
    "1: flyby number\n",
    "\n",
    "2: terrain type determined from mask\n",
    "\n",
    "3: x coordinate in cube\n",
    "\n",
    "4: y coordinate in cube\n",
    "\n",
    "5: latitude\n",
    "\n",
    "6: longitude\n",
    "\n",
    "7: incidence angle\n",
    "\n",
    "8: emission angle\n",
    "\n",
    "9: azimuth angle\n",
    "\n",
    "10: resolution in km\n",
    "\n",
    "11: distance from pixel to a \"no go\" or \"Null\" location in the Mask. This value is present so we can dial how certain we want to be that certain areas are the terrain we say they are. \n",
    "\n",
    "12: phase angle\n",
    "\n",
    "13: 0.93um I/F - There is one of these for each atmospheric window on Titan\n",
    "\n",
    "14: 1.08um I/F\n",
    "\n",
    "15: 1.27um I/F\n",
    "\n",
    "16: 1.59um I/F\n",
    "\n",
    "17: 2.01um I/F\n",
    "\n",
    "18: 2.69um I/F\n",
    "\n",
    "19: 2.79um I/F\n",
    "\n",
    "20: 5.00um I/F\n",
    "\n",
    "Currently, this notebook expects a .csv vile with flyby number and cube number on each entry, but nothing further is required. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06bddbc1-8afe-4526-af17-21b1380268d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETER SETTING\n",
    "#This is where you tell the program what restrictions it should have on its observations.\n",
    "\n",
    "inputFile = \"northPoleCubeList.csv\" #Shoudl be a \"...CubeList\" file made by DatabaseSearcher. Includes flyby and cube number, nothing else. \n",
    "outputName = \"northPolePixelResults.csv\" #Best to put \".csv\" at the end of the name. \n",
    "#IF YOU DO NOT CHANGE THAT IT WILL OVERRIDE THE FILE WITH THIS NAME\n",
    "\n",
    "#Set values you want to check to True.\n",
    "latLonCheck = False #Restricting to specific location ranges\n",
    "flybyCheck = False #Temporal restriction by flyby number\n",
    "resolutionCheck = True #Restrict to a certain resolution classificaiton.\n",
    "\n",
    "maskDistCheck = True\n",
    "maskDistResRelCheck = True #If you set both maskDistChecks to False, \"Null\" values will be accepted. \n",
    "#If all of these are set to False you're printing every single pixel, which will make a gigantic file most likely. Be careful.\n",
    "#That said this IS what you want to do if you don't want to use the mask at all.\n",
    "#If both are set to true, only pixels that satisfy both make it through.\n",
    "\n",
    "#latLonCheck\n",
    "#Bounds are not inclusive, this is to avoid edge case error values. (A point exactly at \"0\" is likely not real). \n",
    "latUpperBound = 90.0\n",
    "latLowerBound = 60.0\n",
    "lonUpperBound = 360.0\n",
    "lonLowerBound = 0.0\n",
    "\n",
    "#flybyCheck\n",
    "flybyUpperBound = 130.0\n",
    "flybyLowerBound = 1.0\n",
    "#use 1 and 2 for TA and TB. \n",
    "\n",
    "#resolutionCheck\n",
    "#Note: resolution 0 pixels are considered errors. \n",
    "resUpperBound = 25.0 #25.0 is considered standard. \n",
    "resLowerBound = 0.0\n",
    "\n",
    "#Mask Distance Test\n",
    "#This is the most unusual but perhaps the most helpful check: how close are we to a pixel we don't trust? \n",
    "#There are two ways to do this check: maskDistCheck (which is just a simple \"less than X km\" test) or maskDistResRelCheck (which compares the distance to an untrusted\n",
    "#pixel to the resolution of the pixel itself. \n",
    "\n",
    "#maskDistcheck\n",
    "maskDistLimit = 50.0\n",
    "#Only distances greater than this (km) will be accepted.\n",
    "\n",
    "#maskDistresRelCheck\n",
    "maskDistRelLimit = 1.0/4.0 # 1/4 is the standard one, meaning the distance to an untrusted pixel must be four times the pixel's resolution to pass judgment. \n",
    "\n",
    "#Things that are NOT sorted here:\n",
    "#Terrain Type. The ModelCreator does that. \n",
    "#Cube coordinates, since there's no reason to sift via those, they just help you locate the pixel again later on. \n",
    "#Viewing Geometry Angles. The models we create want the largest range of these you can obtain for proper tetrahedralization.\n",
    "#I/F of various windows, as restricting these values will create inacurate models at the end. \n",
    "#Cube number, as the flyby number gives enough of a time judgment for our purposes. \n",
    "\n",
    "#Yes the only restrictive thing here that the DatabaseSearcher can't do is the use of the mask. So a standard run will only check against the mask, \n",
    "#assuming the DatabaseSearcher did a good enough job. However the options are still here if you want to slice the DatabaseSearcher's results\n",
    "#into smaller pieces, which can happen regularly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d059f826-d958-4446-b6f4-11eb70f86141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working T24 1548738506_1\n",
      "Working T24 1548739546_1\n",
      "Working T24 1548747455_1\n",
      "Working T24 1548747630_1\n",
      "Working T26 1552200471_1\n",
      "Working T26 1552200618_1\n",
      "Working T26 1552200765_1\n",
      "Working T26 1552200912_1\n",
      "Working T26 1552201059_1\n",
      "Working T26 1552201223_1\n",
      "Working T26 1552201370_1\n",
      "Working T28 1554944126_1\n",
      "Working T28 1554944257_1\n",
      "Working T28 1554944574_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deran\\AppData\\Local\\Temp\\ipykernel_16620\\1997369929.py:270: RuntimeWarning: invalid value encountered in arccos\n",
      "  azim = np.arccos(ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working T31 1559076444_1\n",
      "Working T32 1560454320_1\n",
      "Working T33 1561833549_1\n",
      "Working T35 1567228388_1\n",
      "Working T35 1567229149_1\n",
      "Working T35 1567229818_1\n",
      "Working T35 1567230467_1\n",
      "Working T35 1567236617_1\n",
      "Working T35 1567236713_1\n",
      "Working T42 1585154931_1\n",
      "Working T58 1625759493_1\n",
      "Working T58 1625760170_1\n",
      "Working T64 1640645644_1\n",
      "Working T64 1640646309_1\n",
      "Working T67 1649168886_1\n",
      "Working T67 1649169257_1\n",
      "Working T67 1649170021_1\n",
      "Working T67 1649170981_1\n",
      "Working T67 1649171352_1\n",
      "Working T67 1649172668_1\n",
      "Working T67 1649172733_1\n",
      "Working T67 1649172799_1\n",
      "Working T67 1649172864_1\n",
      "Working T67 1649172994_1\n",
      "Working T67 1649173059_1\n",
      "Working T67 1649173124_1\n",
      "Working T67 1649173189_1\n",
      "Working T67 1649173255_1\n",
      "Working T67 1649173843_1\n",
      "Working T67 1649173943_1\n",
      "Working T67 1649174703_1\n",
      "Working T69 1654398195_1\n",
      "Working T69 1654398683_1\n",
      "Working T69 1654402028_1\n",
      "Working T69 1654403103_1\n",
      "Working T69 1654403828_1\n",
      "Working T69 1654404762_1\n",
      "Working T69 1654405227_1\n",
      "Working T70 1655769946_1\n",
      "Working T70 1655770000_1\n",
      "Working T70 1655770054_1\n",
      "Working T70 1655770590_1\n",
      "Working T70 1655770941_1\n",
      "Working T70 1655772464_1\n",
      "Working T76 1683594434_1\n",
      "Working T76 1683597624_1\n",
      "Working T76 1683597649_1\n",
      "Working T76 1683597673_1\n",
      "Working T76 1683597698_1\n",
      "Working T76 1683597722_1\n",
      "Working T76 1683597747_1\n",
      "Working T76 1683597888_1\n",
      "Working T76 1683597913_1\n",
      "Working T76 1683597937_1\n",
      "Working T81 1706640547_1\n",
      "Working T82 1708327877_1\n",
      "Working T82 1708328593_1\n",
      "Working T82 1708329313_1\n",
      "Working T82 1708330042_1\n",
      "Working T82 1708331084_1\n",
      "Working T82 1708331158_1\n",
      "Working T82 1708331233_1\n",
      "Working T82 1708331308_1\n",
      "Working T82 1708331457_1\n",
      "Working T82 1708331532_1\n",
      "Working T82 1708331607_1\n",
      "Working T82 1708331681_1\n",
      "Working T82 1708331756_1\n",
      "Working T83 1716333759_1\n",
      "Working T83 1716334131_1\n",
      "Working T83 1716334271_1\n",
      "Working T85 1721848119_1\n",
      "Working T85 1721854264_1\n",
      "Working T85 1721854459_1\n",
      "Working T86 1727355885_1\n",
      "Working T86 1727360018_1\n",
      "Working T86 1727360084_1\n",
      "Working T86 1727360149_1\n",
      "Working T86 1727360214_1\n",
      "Working T86 1727360279_3\n",
      "Working T86 1727360344_1\n",
      "Working T86 1727360409_1\n",
      "Working T86 1727360475_1\n",
      "Working T86 1727360540_1\n",
      "Working T86 1727360735_1\n",
      "Working T86 1727360800_1\n",
      "Working T86 1727360866_1\n",
      "Working T86 1727360931_3\n",
      "Working T86 1727361674_1\n",
      "Working T86 1727361805_3\n",
      "Working T86 1727362372_3\n",
      "Working T88 1732865471_1\n",
      "Working T93 1753526378_1\n",
      "Working T93 1753527158_1\n",
      "Working T93 1753527981_1\n",
      "Working T93 1753528655_1\n",
      "Working T93 1753528846_1\n",
      "Working T93 1753530574_1\n",
      "Working T93 1753530947_1\n",
      "Working T93 1753532797_1\n",
      "Working T94 1757656224_1\n",
      "Working T94 1757657221_1\n",
      "Working T94 1757658061_1\n",
      "Working T94 1757658571_1\n",
      "Working T94 1757659622_1\n",
      "Working T94 1757660633_1\n",
      "Working T94 1757662936_1\n",
      "Working T94 1757663476_1\n",
      "Working T94 1757663996_1\n",
      "Working T94 1757664546_1\n",
      "Working T96 1764534076_1\n",
      "Working T96 1764535163_1\n",
      "Working T96 1764535935_1\n",
      "Working T96 1764536760_1\n",
      "Working T96 1764537502_1\n",
      "Working T96 1764538275_1\n",
      "Working T96 1764539107_1\n",
      "Working T96 1764539963_1\n",
      "Working T96 1764540762_1\n",
      "Working T96 1764541575_1\n",
      "Working T96 1764542462_1\n",
      "Working T96 1764544717_1\n",
      "Working T96 1764545191_1\n",
      "Working T96 1764546207_1\n",
      "Working T96 1764547231_1\n",
      "Working T96 1764548302_1\n",
      "Working T96 1764549385_1\n",
      "Working T96 1764549705_1\n",
      "Working T96 1764550229_1\n",
      "Working T97 1767299935_1\n",
      "Working T97 1767300222_1\n",
      "Working T97 1767301842_1\n",
      "Working T97 1767302582_1\n",
      "Working T100 1775561747_1\n",
      "Working T100 1775563631_1\n",
      "Working T104 1787307197_1\n",
      "Working T104 1787308172_5\n",
      "Working T104 1787309222_1\n",
      "Working T104 1787310233_1\n",
      "Working T104 1787310294_1\n",
      "Working T104 1787311722_1\n",
      "Working T104 1787311877_1\n",
      "Working T104 1787311929_1\n",
      "Working T104 1787317297_1\n",
      "Working T104 1787317877_1\n",
      "Working T104 1787319057_1\n",
      "Working T104 1787319637_1\n",
      "Working T104 1787321677_1\n",
      "Working T104 1787322043_1\n",
      "Working T105 1790059135_1\n",
      "Working T105 1790059235_1\n",
      "Working T105 1790066425_1\n",
      "Working T106 1792826660_1\n",
      "Working T108 1799691002_1\n",
      "Working T109 1802456529_1\n",
      "Working T109 1802456559_1\n",
      "Working T109 1802456986_1\n",
      "Working T109 1802461578_1\n",
      "Working T109 1802462455_1\n",
      "Working T110 1805210863_1\n",
      "Working T110 1805211625_1\n",
      "Working T110 1805212073_1\n",
      "Working T112 1814944467_1\n",
      "Working T112 1814944747_1\n",
      "Working T112 1814945844_1\n",
      "Working T112 1814946286_1\n",
      "Working T116 1832992499_1\n",
      "Working T116 1832993063_1\n",
      "Working T119 1841259289_1\n",
      "Working T119 1841265462_1\n"
     ]
    }
   ],
   "source": [
    "#REVISION FOR COLOR MULTI MASK. \n",
    "\n",
    "#Imports\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "#First, read in the data into a matrix. \n",
    "cubeList = []\n",
    "with open(inputFile) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        triplet = [\"A\",\"A\"]\n",
    "        triplet[0] = row[0]\n",
    "        triplet[1] = row[1]\n",
    "        cubeList.append(triplet)\n",
    "        line_count += 1\n",
    "\n",
    "CLRMask = np.load(\"CLRMaskArray.npy\")\n",
    "#Need to make sure this file exists, user. \n",
    "#Colored Mask has all types of terrain marked, as well as no-go zones. \n",
    "\n",
    "CLRMaskDist = np.load(\"CLRMaskArrayDist.npy\") #Holds the actual measures for distance at each point. \n",
    "#Now, for every item in cubeList, we find the file it points to and read it in. \n",
    "#Then we examine those files for *something*. Whatever it is. \n",
    "#Any pixel that matches that something, we keep. \n",
    "\n",
    "open(outputName, 'w').close() #Empty the file.\n",
    "for item in cubeList:\n",
    "    err = 0 #No error by default.\n",
    "\n",
    "    flybyRangeAcceptable = False\n",
    "    flyby = 0.\n",
    "    if (item[0] == \"TA\"): flyby = 1.\n",
    "    elif (item[0] == \"TB\"): flyby = 2.\n",
    "    else: flyby = float(item[0][1:])\n",
    "    if (flybyCheck == True): #Are we in the right flyby range?\n",
    "        if (flybyLowerBound <= flyby and flybyUpperBound >= flyby):\n",
    "            flybyRangeAcceptable = True\n",
    "    else: \n",
    "        flybyRangeAcceptable = True #If we're not checking for time, all of them are fine. \n",
    "\n",
    "\n",
    "    if (flybyRangeAcceptable == True): #Don't bother reading anything in if we don't want this flyby. \n",
    "    \n",
    "        #This code is copy adapted from the VIMS Cube Visualisation Interface Notebook. \n",
    "        #It is complicated.\n",
    "        filepath = \"C:\\\\Users\\\\deran\\\\Desktop\\\\CubeCSVDatabase\\\\\" + item[0] + \"\\\\CM_\" + item[1] + \".cub.csv\"\n",
    "    \n",
    "        #Now we extract the axes file as well...\n",
    "        cubeAxesfp = filepath.removesuffix(\".csv\") + \".axes.csv\"\n",
    "        #and the geo files. \n",
    "        cubeGeofpIR = filepath.removesuffix(\".cub.csv\") + \"_ir_geo.cub.csv\"\n",
    "        cubeGeofpIRaxes = filepath.removesuffix(\".cub.csv\") + \"_ir_geo.cub.axes.csv\"\n",
    "    \n",
    "        #Skeleton code nabbed from https://realpython.com/python-csv/\n",
    "        \n",
    "        #Step 1: use the axes to determine the size of what we're dealing with.\n",
    "        xAxisCube = []\n",
    "        yAxisCube = []\n",
    "        zAxisCube = []\n",
    "        \n",
    "        xAxisGeoIR = []\n",
    "        yAxisGeoIR = []\n",
    "        zAxisGeoIR = []\n",
    "    \n",
    "        try:\n",
    "            with open(cubeAxesfp) as csv_file: #remember to tab.\n",
    "                    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                    line_count = 0\n",
    "                    for row in csv_reader:\n",
    "                        i = 0\n",
    "                        L = len(row)\n",
    "                        while (i < L-1):\n",
    "                            if (line_count == 0):\n",
    "                                xAxisCube.append(row[i])\n",
    "                            elif (line_count == 1):\n",
    "                                yAxisCube.append(row[i])\n",
    "                            elif (line_count == 2):\n",
    "                                zAxisCube.append(row[i])\n",
    "                            i = i+1\n",
    "                        line_count += 1\n",
    "        except:\n",
    "            print(\"No Cube Axes\", item[0], item[1])\n",
    "            err = 1 #whoops.        \n",
    "        try:\n",
    "            with open(cubeGeofpIRaxes) as csv_file: #remember to tab.\n",
    "                    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                    line_count = 0\n",
    "                    for row in csv_reader:\n",
    "                        i = 0\n",
    "                        L = len(row)\n",
    "                        while (i < L-1):\n",
    "                            if (line_count == 0):\n",
    "                                xAxisGeoIR.append(row[i])\n",
    "                            elif (line_count == 1):\n",
    "                                yAxisGeoIR.append(row[i])\n",
    "                            elif (line_count == 2):\n",
    "                                zAxisGeoIR.append(row[i])\n",
    "                            i = i+1\n",
    "                        line_count += 1\n",
    "        except:\n",
    "            print(\"No Geo Axes\", item[0], item[1])\n",
    "            err = 1 #whoops.\n",
    "            \n",
    "        #We now have an x, y, and z axis. x and y axes are just ordinal, but the z axis contains wavelength in microns.\n",
    "        #The lengths of these arrays tell us how to extract the data.\n",
    "        \n",
    "        cubeData = [[[0 for x in range(len(zAxisCube))] for x in range(len(yAxisCube))] for x in range(len(xAxisCube))]\n",
    "        geoIRData = [[[0 for x in range(len(zAxisGeoIR))] for x in range(len(yAxisGeoIR))] for x in range(len(xAxisGeoIR))]\n",
    "        \n",
    "        #The above holds the data of the cube itself. \n",
    "        try:\n",
    "            with open(filepath) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                line_count = 0\n",
    "                i, j, k = 0, 0, 0\n",
    "                for row in csv_reader:\n",
    "                    while (i < len(xAxisCube)):\n",
    "                        cubeData[i][j][k] = float(row[i])\n",
    "                        if (math.isnan(cubeData[i][j][k])):\n",
    "                            cubeData[i][j][k] = 0 #We set nans to zero to allow plotting to take place, careful!\n",
    "                        elif (cubeData[i][j][k] < 0):\n",
    "                            cubeData[i][j][k] = 0 #Negative values are nonsense.\n",
    "                        elif (cubeData[i][j][k] > 1):\n",
    "                            cubeData[i][j][k] = 1 #Make saturation obvious? Keep it from overloading. \n",
    "                        i = i + 1\n",
    "                    i = 0\n",
    "                    j = j + 1\n",
    "                    if (j >= len(yAxisCube)):\n",
    "                        j = 0\n",
    "                        k = k + 1\n",
    "                    line_count += 1\n",
    "        except:\n",
    "            print(\"No Cube File (how?)\", item[0], item[1])\n",
    "            err = 1 #whoops.\n",
    "        try:\n",
    "            with open(cubeGeofpIR) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                line_count = 0\n",
    "                i, j, k = 0, 0, 0\n",
    "                for row in csv_reader:\n",
    "                    while (i < len(xAxisGeoIR)):\n",
    "                        geoIRData[i][j][k] = float(row[i])\n",
    "                        if (math.isnan(geoIRData[i][j][k])):\n",
    "                            geoIRData[i][j][k] = 0 #We set nans to zero to allow plotting to take place, careful!\n",
    "                        elif (geoIRData[i][j][k] < -1000):\n",
    "                            geoIRData[i][j][k] = 0 #The default value is an extremely negative number. Scrub it.\n",
    "                        i = i + 1\n",
    "                    i = 0\n",
    "                    j = j + 1\n",
    "                    if (j >= len(yAxisGeoIR)):\n",
    "                        j = 0\n",
    "                        k = k + 1\n",
    "                    line_count += 1\n",
    "        except:\n",
    "            print(\"No Geo File\", item[0], item[1])\n",
    "            err = 1 #Whoops.\n",
    "        #The data is now read in.\n",
    "    \n",
    "        #BOOKKEEPING: declare where the windows are. \n",
    "        windowum = [0.933078, 1.08183, 1.27813, 1.59018, 2.01781, 2.69620, 2.79889, 5.00576]\n",
    "        windowInd = [80, 108, 120, 139, 165, 206, 212, 344]\n",
    "        windowIndAlt = [3,12,24,43,69,110,116,248]\n",
    "        if (len(zAxisCube) <= 256):\n",
    "            windowInd = windowIndAlt #Simetimes the cubes have different indeces. It's weird,  yeah, but this is how we check for that. \n",
    "    \n",
    "        print(\"Working\", item[0], item[1])\n",
    "            \n",
    "        #Now we can do stuff with the data. In this case, we need to examine every pixel and print out the \"viable\" ones to a file.\n",
    "        if (err == 0):\n",
    "            with open(outputName, 'a') as dataEntry:  \n",
    "                x,y = 0,0 \n",
    "                while (x < len(xAxisCube)):\n",
    "                    y = 0\n",
    "                    while (y < len(yAxisCube)):\n",
    "                        #Inintial checks of pixel locaiton and resolution. Only continue if tests passed. \n",
    "                        if ((latLonCheck == False) or \n",
    "                            (geoIRData[x][y][0] > latLowerBound and geoIRData[x][y][0] < latUpperBound and \n",
    "                             geoIRData[x][y][1] > lonLowerBound and geoIRData[x][y][1] < lonUpperBound)): \n",
    "                            if((resolutionCheck == False) or \n",
    "                               (resUpperBound > geoIRData[x][y][2] and \n",
    "                                resLowerBound < geoIRData[x][y][2] and geoIRData[x][y][2] != 0.0)):\n",
    "    \n",
    "                                #Now at this point we perform the mask test, but we have to start gatehring some values before we can do that. \n",
    "        \n",
    "                                lat = geoIRData[x][y][0]\n",
    "                                lon = geoIRData[x][y][1]\n",
    "                                #Round to the nearest whole number.\n",
    "                                lat = int(np.rint(lat))\n",
    "                                lon = 360 - int(np.rint(lon)) #Have to flip our longitude. \n",
    "                                #not because it's wrong, but because the INDEX of the MASK is FLIPPED.\n",
    "                                if (lon >= 360): lon = 0\n",
    "                                #Now these are our latlon coordinates. We can use them to find the mask we need.\n",
    "        \n",
    "                                #But first, we have an issue. The distance to \"bad pixel\" is recorded in each pixel... but \n",
    "                                #How do we exctract it? Well first we need to find an existing value.\n",
    "                                distMeasure = 1000 #A ridiculously oversized number.\n",
    "                                if(CLRMask[90-lat][lon][0] != 0):\n",
    "                                    distMeasure = CLRMaskDist[90-lat][lon][0]\n",
    "                                elif(CLRMask[90-lat][lon][1] != 0):\n",
    "                                    distMeasure = CLRMaskDist[90-lat][lon][1]\n",
    "                                elif(CLRMask[90-lat][lon][2] != 0):\n",
    "                                    distMeasure = CLRMaskDist[90-lat][lon][2]  \n",
    "        \n",
    "                                maskTest = False\n",
    "\n",
    "                                if (maskDistCheck == False and maskDistResRelCheck == False):\n",
    "                                    maskTest = True #Accept everything. \n",
    "                                else:\n",
    "                                    if ((CLRMask[90-lat][lon][0] == 0 and CLRMask[90-lat][lon][1] == 0 and CLRMask[90-lat][lon][2] == 0)==False): #Black areas are no-go-zones, \n",
    "                                        #avoid them.\n",
    "                                        if (maskDistResRelCheck == True):\n",
    "                                            if ( (geoIRData[x][y][2] <= maskDistRelLimit*(distMeasure*100./255.)) and (geoIRData[x][y][2] != 0)): #0 value is probably an error, throw it out.\n",
    "                                                maskTest = True\n",
    "                                                if (maskDistCheck == True):\n",
    "                                                    if ( (distMeasure*100./255.) < maskDistLimit ):\n",
    "                                                        maskTest = False #If doing both tests, both must be true to be used.\n",
    "                                        elif (maskDistCheck == True):\n",
    "                                            if ( (distMeasure*100./255.) >= maskDistLimit ):\n",
    "                                                maskTest = True \n",
    "                                        #The \"else\" case would be when neither is used, which we already accounted for.\n",
    "                                \n",
    "                                if (maskTest == True): #Do not bother with anything the mask hates.\n",
    "                                    temp = np.transpose(cubeData)\n",
    "                                    #Okay so guess what it works we have what we need time to actually GATHER ALL THE DATA.\n",
    "                                    outfile = item[0] + \",\" #Cube number.\n",
    "                                    outfile = outfile + item[1] + \",\" #Flyby number\n",
    "                                    #outfile = outfile + item[2] + \",\" #Resolution classification \n",
    "        \n",
    "                                    #Color Determination: what type of surface are we looking at? Label it!\n",
    "                                    color = \"Null\" #No classification. Would be what a bad pixel recieved\n",
    "                                    #But it should not be possible to get one at this point.\n",
    "                                    if (CLRMask[90-lat][lon][0] == 0):\n",
    "                                        if (CLRMask[90-lat][lon][1] == 0):\n",
    "                                            if (CLRMask[90-lat][lon][2] == 0):\n",
    "                                                color = \"Null\" #Black for no-go zone...\n",
    "                                            else:\n",
    "                                                color = \"Lake\" #Blue for Craters\n",
    "                                        else:\n",
    "                                            if (CLRMask[90-lat][lon][2] == 0):\n",
    "                                                color = \"Xanadu\" #Green for Xanadu\n",
    "                                            else:\n",
    "                                                color = \"Crater\" #Cyan for Craters\n",
    "                                    else:\n",
    "                                        if (CLRMask[90-lat][lon][1] == 0):\n",
    "                                            if (CLRMask[90-lat][lon][2] == 0):\n",
    "                                                color = \"Dunes\" #Red for dunes\n",
    "                                            else:\n",
    "                                                color = \"Labyrinth\" #Magenta for Labyrinth\n",
    "                                        else:\n",
    "                                            if (CLRMask[90-lat][lon][2] == 0):\n",
    "                                                color = \"Hummocky\" #Yellow for \"hummocky\" \n",
    "                                            else:\n",
    "                                                color = \"Plains\" #White for Plains\n",
    "        \n",
    "                                    outfile = outfile + color + \",\" #Terrain type determined from mask color\n",
    "                                    \n",
    "                                    outfile = outfile + str(x) + \",\" + str(y) + \",\" #Pixel Coordinates\n",
    "                                    outfile = outfile + str(geoIRData[x][y][0]) + \",\" + str(geoIRData[x][y][1]) + \",\" #Latlon\n",
    "                                    #Fortunately we read lon in directly so the fact that we flipped it isn't an issue.\n",
    "                                    inci = geoIRData[x][y][5]\n",
    "                                    emis = geoIRData[x][y][6]\n",
    "                                    azim = 0.\n",
    "                                    #Azimuth formula from Jason Barnes' phasecurve.c++\n",
    "                                    p = geoIRData[x][y][4] #used to calculate azimuth.\n",
    "                                    ratio = -(np.cos(np.radians(p)) - np.cos(np.radians(inci))* np.cos(np.radians(emis)))/(np.sin(np.radians(inci))*np.sin(np.radians(emis)))\n",
    "                                    azim = np.arccos(ratio)\n",
    "                                    #Of course, this might be nan-ing. All the nans need their own values.\n",
    "                                    if((math.isnan(azim) == True) and (ratio>0.)):\n",
    "                                        azim = 0.\n",
    "                                    elif((math.isnan(azim) == True) and (ratio<0.)):\n",
    "                                        azim = 0.\n",
    "                                    elif((inci==0) and (emis==0)):\n",
    "                                        azim = 0.\n",
    "                                    elif(math.isnan(azim) == True):\n",
    "                                        print(\"Well you broke it, great. (Azimuth is nan, but could not be set to anything else.)\")\n",
    "                                    if (inci < 0):\n",
    "                                        inci = 0\n",
    "                                    elif (inci > 100):\n",
    "                                        inci = 100\n",
    "                                    if (emis < 0):\n",
    "                                        emis = 0\n",
    "                                    elif (emis > 90):\n",
    "                                        emis = 90\n",
    "                                    if (azim < 0):\n",
    "                                        azim = 0\n",
    "                                    if (azim > 180):\n",
    "                                        azim = 180\n",
    "                                    outfile = outfile + str(inci) + \",\" + str(emis) + \",\" #inci emis\n",
    "                                    outfile = outfile + str(math.degrees(azim)) + \",\" #azimuth\n",
    "                                    outfile = outfile + str(geoIRData[x][y][2]) + \",\" + str(distMeasure*100./255.) + \",\" + str(geoIRData[x][y][4]) + \",\" \n",
    "                                    #res distanceInMask phase\n",
    "                                    #Now we need the window wavelengths, which means we need to *read* the data itself.\n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[0]])[x][y]) + \",\" \n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[1]])[x][y]) + \",\" \n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[2]])[x][y]) + \",\" \n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[3]])[x][y]) + \",\" \n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[4]])[x][y]) + \",\" \n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[5]])[x][y]) + \",\" \n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[6]])[x][y]) + \",\"\n",
    "                                    outfile = outfile + str(np.transpose(temp[windowInd[7]])[x][y]) + \",\" + \"\\n\"        \n",
    "                                    #print(outfile)\n",
    "                                    dataEntry.write(outfile)\n",
    "                        y=y+1\n",
    "                    x=x+1 \n",
    "    \n",
    "#ADD SANITY CHECKER HERE IF NEEDED\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81eacc5-2497-48e6-915a-f57062c30762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
